{"cells": [{"cell_type": "markdown", "id": "7b7983c2-3d57-42d3-8431-85265cbd5f22", "metadata": {}, "source": "# What is covered?\n1. Creating SparkSession\n2. Reading ratings data from cloud storage bucket\n3. Data preparation\n4. Training ALS model on ratings data\n5. Calculating the RMSE score and populating prediction"}, {"cell_type": "code", "execution_count": 1, "id": "361d740b-4779-4c2b-a1aa-90baccf65731", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, BooleanType, TimestampType, IntegerType"}, {"cell_type": "code", "execution_count": 2, "id": "0de5504a-d30c-435c-8ef1-3b7c3ef9d959", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/06/23 00:10:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "# create spark session\nspark=SparkSession \\\n    .builder \\\n    .appName(\"Data to BQ\") \\\n    .config(\"spark.jars\", \"gs://spark-lib/bigquery/spark-3.5-bigquery-0.38.0.jar\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "db7206b7-462c-4fbf-bdce-627baa6c4858", "metadata": {"tags": []}, "outputs": [], "source": "data_file_uri = \"gs://als-exp/data/ratings.csv\"\ntmp_bucket_uri = \"gs://als-exp/tmp\"\nproject_id = \"recs-exp\"\nbq_table_name = f\"{project_id}.books.ratings\"\n\nschema = StructType([\n    StructField(\"user_id\", IntegerType(), True),\n    StructField(\"book_id\", IntegerType(), True),\n    StructField(\"rating\", IntegerType(), True)\n])\n\n# read ratings data into a dataframe\ndataframe = spark.read.format(\"csv\").schema(schema).load(data_file_uri)"}, {"cell_type": "markdown", "id": "acf8aae8-d96a-49ca-a0eb-7be69afcc764", "metadata": {"tags": []}, "source": "### Optional: Storing data to BigQuery Table"}, {"cell_type": "code", "execution_count": 9, "id": "42da7208-ec9a-4a02-8201-799ffb84ab55", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "dataframe.select(\"user_id\", \"book_id\", \"rating\").write \\\n    .format(\"com.google.cloud.spark.bigquery.v2.Spark34BigQueryTableProvider\")\\\n    .option('table', bq_table_name) \\\n    .option('temporaryGcsBucket',tmp_bucket_uri) \\\n    .mode('append') \\\n    .save()\n\nspark.stop()"}, {"cell_type": "markdown", "id": "0814775d-284a-4d7c-8f33-f74247dde6e4", "metadata": {"tags": []}, "source": "### Data Preparation"}, {"cell_type": "code", "execution_count": 4, "id": "c690f322-2472-41e8-ac23-85e0187990d1", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+-------+------+\n|user_id|book_id|rating|\n+-------+-------+------+\n|      1|    258|     5|\n|      2|   4081|     4|\n|      2|    260|     5|\n|      2|   9296|     5|\n|      2|   2318|     3|\n|      2|     26|     4|\n|      2|    315|     3|\n|      2|     33|     4|\n|      2|    301|     5|\n|      2|   2686|     5|\n|      2|   3753|     5|\n|      2|   8519|     5|\n|      4|     70|     4|\n|      4|    264|     3|\n|      4|    388|     4|\n|      4|     18|     5|\n|      4|     27|     5|\n|      4|     21|     5|\n|      4|      2|     5|\n|      4|     23|     5|\n+-------+-------+------+\nonly showing top 20 rows\n\n"}], "source": "dataframe = dataframe.na.drop()\ndataframe.show()\n# creating train and test split\ntrain_data, test_data = dataframe.randomSplit([0.80,0.20])"}, {"cell_type": "markdown", "id": "cad27e38-d88b-4965-bae7-10a0d33ba516", "metadata": {}, "source": "### Train ALS model"}, {"cell_type": "code", "execution_count": 5, "id": "eb06eec4-1ecc-4713-a4f4-53709221ccf1", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline"}, {"cell_type": "code", "execution_count": null, "id": "e45863a4-6ecc-4c63-bc91-1a0454152eb6", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 12:===================================================>     (9 + 1) / 10]\r"}], "source": "# Train the ALS model on the training set\nals_model = ALS(maxIter=5, regParam= 0.01, userCol=\"user_id\", itemCol=\"book_id\", ratingCol=\"rating\", rank=5, coldStartStrategy=\"drop\")\nals_model = als_model.fit(train_data)\n\n# Make predictions on the testing set\npredictions = als_model.transform(test_data)\npredictions = predictions.dropna()\n\n# Evaluate the model using RMSE\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\n\nprint(\"Root-mean-square error = \" + str(rmse))"}, {"cell_type": "code", "execution_count": null, "id": "a2878fcf-96da-4b0c-b42b-b5ea67f851cf", "metadata": {"tags": []}, "outputs": [], "source": "predictions.show()"}, {"cell_type": "markdown", "id": "ecceccc9-addf-4ad1-84cc-9101d65aa842", "metadata": {}, "source": "## Conclusion\nIn this article, we implemented ALS model training on a PySpark cluster. The ALS (Alternating Least Squares) algorithm is very useful when working with big data and developing collaborative filtering recommendation systems. ALS effectively handles the cold start problem in recommendations and leverages the power of distributed computing clusters, such as Apache Spark, to train models on large datasets efficiently with reduced training time."}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}